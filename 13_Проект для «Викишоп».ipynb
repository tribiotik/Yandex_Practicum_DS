{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Привет, меня зовут Артем Хуршудов. Сегодня я проверю твой проект.\n",
    "<br> Дальнейшее общение будет происходить на \"ты\" если это не вызывает никаких проблем.\n",
    "<br> Желательно реагировать на каждый мой комментарий ('исправил', 'не понятно как исправить ошибку', ...)\n",
    "<br> Пожалуйста, не удаляй комментарии ревьюера, так как они повышают качество повторного ревью.\n",
    "\n",
    "Комментарии будут в <font color='green'>зеленой</font>, <font color='blue'>синей</font> или <font color='red'>красной</font> рамках:\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Если все сделано отлично\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Если можно немного улучшить\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка:</b> Если требуются исправления. Работа не может быть принята с красными комментариями.\n",
    "</div>\n",
    "\n",
    "-------------------\n",
    "\n",
    "Будет очень хорошо, если ты будешь помечать свои действия следующим образом:\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента:</b> ...\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Изменения:</b> Были внесены следующие изменения ...\n",
    "</div>\n",
    "\n",
    "<font color='green'><b>Полезные (и просто интересные) материалы:</b></font> \\\n",
    "Для работы с текстами используют и другие подходы. Например, сейчас активно используются RNN (LSTM) и трансформеры (BERT и другие с улицы Сезам, например, ELMO). НО! Они не являются панацеей, не всегда они нужны, так как и TF-IDF или Word2Vec + модели из классического ML тоже могут справляться. \\\n",
    "BERT тяжелый, существует много его вариаций для разных задач, есть готовые модели, есть надстройки над библиотекой transformers. Если, обучать BERT на GPU (можно в Google Colab или Kaggle), то должно быть побыстрее.\\\n",
    "https://huggingface.co/transformers/model_doc/bert.html \\\n",
    "https://t.me/renat_alimbekov \\\n",
    "https://colah.github.io/posts/2015-08-Understanding-LSTMs/ - Про LSTM \\\n",
    "https://web.stanford.edu/~jurafsky/slp3/10.pdf - про энкодер-декодер модели, этеншены\\\n",
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html - официальный гайд\n",
    "по трансформеру от создателей pytorch\\\n",
    "https://transformer.huggingface.co/ - поболтать с трансформером \\\n",
    "Библиотеки: allennlp, fairseq, transformers, tensorflow-text — множествореализованных\n",
    "методов для трансформеров методов NLP \\\n",
    "Word2Vec https://radimrehurek.com/gensim/models/word2vec.html \n",
    "\n",
    "<font color='green'>Пример BERT с GPU:\n",
    "```python\n",
    "%%time\n",
    "from tqdm import notebook\n",
    "batch_size = 2 # для примера возьмем такой батч, где будет всего две строки датасета\n",
    "embeddings = [] \n",
    "for i in notebook.tqdm(range(input_ids.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(input_ids[batch_size*i:batch_size*(i+1)]).cuda() # закидываем тензор на GPU\n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]).cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.cuda()\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy()) # перевод обратно на проц, чтобы в нумпай кинуть\n",
    "        del batch\n",
    "        del attention_mask_batch\n",
    "        del batch_embeddings\n",
    "        \n",
    "features = np.concatenate(embeddings) \n",
    "```\n",
    "Можно сделать предварительную проверку на наличие GPU.\\\n",
    "Например, так: ```device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")```\\\n",
    "Тогда вместо .cuda() нужно писать .to(device)\n",
    "\n",
    "Если понравилась работа с текстами, то можешь посмотреть очень интересный (но очень-очень сложный) курс лекций: https://github.com/yandexdataschool/nlp_course .\n",
    "</font>\n",
    "\n",
    "### <font color='orange'>Общее впечатление</font>\n",
    "* Большое спасибо за проделанную работу. Видно, что приложено много усилий.\n",
    "* Радует, что ноутбук хорошо структурирован. Приятно проверять такие работы.\n",
    "* Отлично, что стоп-слова были исключены при векторизации!\n",
    "* Над этим проектом нужно будет еще немного поработать. Однако, изменения не должны занять много времени.\n",
    "* В работе я оставил несколько советов. Буду рад, если ты учтешь их.\n",
    "* С радостью отвечу на твои вопросы, если они есть. Лучше всего их собрать в следующей ячейке. Жду новую версию проекта."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>Общее впечатление (ревью 2)</font>\n",
    "* Для удобства все новые комментарии обозначены фразой \"ревью 2\".\n",
    "* Возможно, ты отправил не последнюю версию проекта?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента:</b> Я если честно не понимаю что произошло. И как так вышло, что мне вернулся старый проект. Я отправлял доработаную версию с прогнаным несколько раз кодом. Знатно пригорает у меня!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента:</b>  В общем чек поинта почему то тоже автоматического нет и копию себе на комп я тоже не сохранил. Доработал по новой.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>Общее впечатление (ревью 3)</font>\n",
    "* Все новые комментарии обозначены фразой \"ревью 3\".\n",
    "* Удачи в доработке!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>Общее впечатление (ревью 4)</font>\n",
    "* После исправлений проект улучшился и теперь он может быть зачтен.\n",
    "* В проекте еще был вопрос, почему даунсемплинг не работает. Основная причина в том, что ты удаляешь часть текстов и модель \"узнает о существовании меньшего количества слов\". Может так случится, что слово Х встречается в треине и в тесте всего по 1 разу и ты его удалишь из треина при даунсемплинге. \n",
    "* Удачи в дальнейшем обучении и следующих работах!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Общее-впечатление\" data-toc-modified-id=\"Общее-впечатление-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление</font></a></span></li><li><span><a href=\"#Общее-впечатление-(ревью-2)\" data-toc-modified-id=\"Общее-впечатление-(ревью-2)-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление (ревью 2)</font></a></span></li><li><span><a href=\"#Общее-впечатление-(ревью-3)\" data-toc-modified-id=\"Общее-впечатление-(ревью-3)-0.3\"><span class=\"toc-item-num\">0.3&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление (ревью 3)</font></a></span></li><li><span><a href=\"#Общее-впечатление-(ревью-4)\" data-toc-modified-id=\"Общее-впечатление-(ревью-4)-0.4\"><span class=\"toc-item-num\">0.4&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление (ревью 4)</font></a></span></li></ul></li><li><span><a href=\"#Импорт-библиотек\" data-toc-modified-id=\"Импорт-библиотек-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Импорт библиотек</a></span></li><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Модель-Decision-Tree-(Дерево-решений)\" data-toc-modified-id=\"Модель-Decision-Tree-(Дерево-решений)-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Модель Decision Tree (Дерево решений)</a></span></li><li><span><a href=\"#Модель-Random-Forest-(Случайный-лес)\" data-toc-modified-id=\"Модель-Random-Forest-(Случайный-лес)-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Модель Random Forest (Случайный лес)</a></span></li><li><span><a href=\"#Модель-Logistic-Regression-(Логическая-регрессия)\" data-toc-modified-id=\"Модель-Logistic-Regression-(Логическая-регрессия)-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Модель Logistic Regression (Логическая регрессия)</a></span></li><li><span><a href=\"#SMOTE\" data-toc-modified-id=\"SMOTE-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>SMOTE</a></span></li><li><span><a href=\"#Модель-Decision-Tree-(после-SMOTE)\" data-toc-modified-id=\"Модель-Decision-Tree-(после-SMOTE)-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Модель Decision Tree (после SMOTE)</a></span></li><li><span><a href=\"#Модель-Logistic-Regression-(после-SMOTE)\" data-toc-modified-id=\"Модель-Logistic-Regression-(после-SMOTE)-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Модель Logistic Regression (после SMOTE)</a></span></li><li><span><a href=\"#Модель-Random-Forest-(после-SMOTE)\" data-toc-modified-id=\"Модель-Random-Forest-(после-SMOTE)-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>Модель Random Forest (после SMOTE)</a></span></li><li><span><a href=\"#LogisticRegression--с-подбором-параметра-&quot;С&quot;\" data-toc-modified-id=\"LogisticRegression--с-подбором-параметра-&quot;С&quot;-3.8\"><span class=\"toc-item-num\">3.8&nbsp;&nbsp;</span>LogisticRegression  с подбором параметра \"С\"</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Выводы</a></span><ul class=\"toc-item\"><li><span><a href=\"#upd.\" data-toc-modified-id=\"upd.-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>upd.</a></span></li></ul></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install imblearn --user\n",
    "#!conda install -c conda-forge imbalanced-learn\n",
    "#!pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pymystem3 import Mystem\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.utils import shuffle\n",
    "#!pip install imblearn\n",
    "from imblearn.over_sampling import SMOTE  #почему то не импортируется\n",
    "\n",
    "def line():\n",
    "    print('__________________________________')\n",
    "RND=12345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Отлично, что все импорты собраны в первой ячейке ноутбука! Если у того, кто будет запускать твой ноутбук будут отсутствовать некоторые библиотеки, то он это увидит сразу, а не в процессе!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159566  \":::::And for the second time of asking, when ...      0\n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159569  And it looks like it was actually you who put ...      0\n",
       "159570  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159571 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "display(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропусков \n",
      "text     0\n",
      "toxic    0\n",
      "dtype: int64\n",
      "Количество дубликатов \n",
      "0\n",
      "Баланс классов \n",
      "0    0.898321\n",
      "1    0.101679\n",
      "Name: toxic, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Количество пропусков ', df.isna().sum(), sep='\\n')\n",
    "print('Количество дубликатов ', df.duplicated().sum(), sep='\\n')\n",
    "print('Баланс классов ', df['toxic'].value_counts(normalize = (0,1)), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Для наглядности построю график несбалансированности классов\n",
    "df['toxic'].value_counts(normalize = (0,1)).plot(kind = 'bar', grid = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеем датасет 2 столбца и 159 571. Пропуски отсутствуют. Дубликатов нет. Наблюдается сильный дисбаланс данных в столбце toxic: 0 ~ 90% и 1 ~ 10%. Соответственно токсичных коментов всего 10%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Данные загружены корреткно. Радует, что баланс классов был изучен.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemma_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                          lemma_text  \n",
       "0  explanation why the edits made under my userna...  \n",
       "1  d aww he match this background colour i m seem...  \n",
       "2  hey man i m really not trying to edit war it s...  \n",
       "3  more i can t make any real suggestion on impro...  \n",
       "4  you sir are my hero any chance you remember wh...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#лематизирую текст\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemma_text(text):\n",
    "    clean = \" \".join(re.sub(r'[^a-zA-z]', ' ', text).lower().split())\n",
    "    word_list = nltk.word_tokenize(clean)\n",
    "    lemmatized = ' '.join([lemmatizer.lemmatize(w) for w in word_list])    \n",
    "    return lemmatized\n",
    "\n",
    "df['lemma_text'] = df['text'].apply(lemma_text)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemma_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic                                         lemma_text\n",
       "0      0  explanation why the edits made under my userna...\n",
       "1      0  d aww he match this background colour i m seem...\n",
       "2      0  hey man i m really not trying to edit war it s...\n",
       "3      0  more i can t make any real suggestion on impro...\n",
       "4      0  you sir are my hero any chance you remember wh..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# удаляю столбец с исходным текстом\n",
    "df = df.drop(['text'], axis=1)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Очистка и лемматизация были сделаны правильно, молодец!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79785, 1) (39893, 1) (39893, 1)\n",
      "(79785,) (39893,) (39893,)\n"
     ]
    }
   ],
   "source": [
    "# Определяю признаки и цель\n",
    "features = df.drop(['toxic'], axis=1)\n",
    "target = df['toxic']\n",
    "\n",
    "# Выполняю разделение выборки на обучающу валидационную и тестовую в пропорции 50:25:25\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features, target, test_size=0.5, \n",
    "                                                                              random_state=RND)\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_valid, target_valid, test_size=0.5, \n",
    "                                                                              random_state=RND )\n",
    "print(features_train.shape, features_valid.shape, features_test.shape)\n",
    "print(target_train.shape, target_valid.shape, target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Векторизация текста\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "\n",
    "features_train = count_tf_idf.fit_transform(features_train['lemma_text'])\n",
    "features_valid = count_tf_idf.transform(features_valid['lemma_text'])\n",
    "features_test = count_tf_idf.transform(features_test['lemma_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаки и цель определены. Выборки разделены, размерность соблюдена."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Разбиение было сделано правильно. Отлично, что векторизатор был обучен только на тренировочной части данных.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Приводить тексты к юникоду не имеет смысла, так как они все на английском.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента:</b> Спасибо за совет. Чуть поправил код.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех (ревью 2):</b> ОК.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель Decision Tree (Дерево решений)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_counts = 3\n",
    "#for depth in range(1, 60, 10):\n",
    "#    classificator = DecisionTreeClassifier(class_weight='balanced',random_state=RND, max_depth=depth)\n",
    "#    f1_score = cross_val_score(classificator, features_train, target_train, cv=cv_counts, scoring='f1').mean()\n",
    "    \n",
    "#    line()\n",
    "#    print(\"max_depth =\", depth, \": \", end='')\n",
    "#    print('f1_score = ', f1_score)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________________________\n",
    "max_depth = 1 : f1_score =  0.2675377028062224\n",
    "__________________________________\n",
    "max_depth = 11 : f1_score =  0.5539359952682256\n",
    "__________________________________\n",
    "max_depth = 21 : f1_score =  0.5923474314485692\n",
    "__________________________________\n",
    "max_depth = 31 : f1_score =  0.6050516084509338\n",
    "__________________________________\n",
    "max_depth = 41 : f1_score =  0.6219568723735517\n",
    "__________________________________\n",
    "max_depth = 51 : f1_score =  0.6207814351742419"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Напомню, что внутри кросс-валидации происходит разбиение выборки на треин и валидацию. Однако, в таком случае векторизатор обучен на всей выборке, а это не совсем корректно. Для избежания такого эффекта можно использовать <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\">пайплайн</a>. <a href=\"https://medium.com/analytics-vidhya/ml-pipelines-using-scikit-learn-and-gridsearchcv-fe605a7f9e05\">Тут</a> есть пример.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> При использовании кросс-валидации можно вообще не выделять валидационный набор.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель Random Forest (Случайный лес)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for est in range(1, 100, 20):\n",
    "#    for depth in range(40, 100, 10):\n",
    "#        classificator = RandomForestClassifier(class_weight='balanced',random_state=RND, n_estimators= est, max_depth=depth)\n",
    "#        f1_score = cross_val_score(classificator, features_train, target_train, cv=cv_counts, scoring='f1').mean()\n",
    "        \n",
    "#        line()\n",
    "#        print(\"n_estimators =\", est, \": \", end='')\n",
    "#        print(\"max_depth =\", depth, \": \", end='')\n",
    "#        print('f1_score = ', f1_score)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная модель дала очень плохой результат. f1 не выше 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель Logistic Regression (Логическая регрессия)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "#for i in solvers:\n",
    "#    classificator = LogisticRegression(class_weight='balanced',random_state=RND,solver= i)\n",
    "#    f1_score = cross_val_score(classificator, features_train, target_train, cv=cv_counts, scoring='f1').mean()\n",
    "    \n",
    "#    line()\n",
    "#    print(\"solvers =\", i, \": \", end='')\n",
    "#    print('f1_score = ', f1_score)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solvers = newton-cg : f1_score =  0.7424025730537895\n",
    "__________________________________\n",
    "solvers = lbfgs : f1_score =  0.7423678115351944\n",
    "__________________________________\n",
    "solvers = liblinear : f1_score =  0.7424368124322299\n",
    "__________________________________\n",
    "solvers = sag : f1_score =  0.7424025730537895"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Тут можно было подобрать параметр С.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#rf_params = {\n",
    "#        'n_estimators' : range(50, 101, 10),\n",
    "#        'max_depth' : range(5, 15, 2),\n",
    "#        'verbose' : [0],\n",
    "#        'random_state' : [RND] \n",
    "#        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf_grid = GridSearchCV(RandomForestRegressor(), param_grid = rf_params, refit=False, scoring='f1', cv=cv_counts)\n",
    "#rf_grid.fit(features_train, target_train)\n",
    "\n",
    "#rf_best_params = rf_grid.best_params_\n",
    "#rf_m = RandomForestRegressor(**rf_best_params)\n",
    "#rf_m.fit(features_train, target_train)\n",
    "    \n",
    "#rf_test_pred = rf_m.predict(features_test)\n",
    "\n",
    "#print('Лучшие гиперпараметры: ', rf_best_params)\n",
    "#print(\"f1_score = \", f1_score(target_test, lr_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели с применением параметра class_weight='balanced' для борьбы с балансом коассов не дало требуемого результата.\n",
    "Перебор параметров при помощи GridSearchCV у меня не получился все время вылетают варнингс , а результата нет. Разобраться почему так получается не удалось. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# борьба с балансом классов через downsample\n",
    "\n",
    "df_train = df.iloc[target_train.index]\n",
    "\n",
    "target_train0 = df_train[df_train['toxic'] == 0]['toxic']\n",
    "target_train1 = df_train[df_train['toxic'] == 1]['toxic']\n",
    "\n",
    "target_train0_downsample = target_train0.sample(target_train1.shape[0],\n",
    "                                                                    random_state=RND)\n",
    "target_train_downsample = pd.concat([target_train0_downsample, target_train1])\n",
    "\n",
    "features_train_downsample = df.iloc[target_train_downsample.index]\n",
    "features_train_downsample, target_train_downsample = shuffle(features_train_downsample,target_train_downsample,random_state=RND)\n",
    "                                                             \n",
    "                                                          \n",
    "features_train_downsample = count_tf_idf.transform(features_train_downsample['lemma_text'])\n",
    "\n",
    "# Провекра размерности классов\n",
    "#target_train_downsample.value_counts(normalize = (0,1)).plot(kind = 'bar', grid = True)\n",
    "#plt.show()\n",
    "\n",
    "                                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка:</b> Почему ты тут определил треин как весь датасет?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех (ревью 2):</b> Верно.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента :</b> Удалось установить SMOTE. Поэтому решил работать с ним.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state = RND)\n",
    "\n",
    "X_train_res, y_train_res = sm.fit_resample(features_train, target_train.ravel())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель Decision Tree (после SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for depth in range(40, 100, 10):\n",
    "#    classificator = DecisionTreeClassifier(random_state=RND, max_depth=depth)\n",
    "#    f1_score = cross_val_score(classificator, X_train_res, y_train_res, cv=cv_counts,\n",
    "#                               scoring='f1').mean()\n",
    "    \n",
    "#    line()\n",
    "#    print(\"max_depth =\", depth, \": \", end='')\n",
    "#    print('f1_score = ', f1_score)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_depth = 40 : f1_score =  0.8773751822158848\n",
    "__________________________________\n",
    "max_depth = 50 : f1_score =  0.89629768016232\n",
    "__________________________________\n",
    "max_depth = 60 : f1_score =  0.908628754381369\n",
    "__________________________________\n",
    "max_depth = 70 : f1_score =  0.9181720548962197\n",
    "__________________________________\n",
    "max_depth = 80 : f1_score =  0.9248115572091885\n",
    "__________________________________\n",
    "max_depth = 90 : f1_score =  0.9291698095189149"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtc = DecisionTreeClassifier()\n",
    "#dtc.fit(features_train, target_train.ravel())\n",
    "\n",
    "#predictions = dtc.predict(features_test)\n",
    "\n",
    "#print(classification_report(target_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка:</b> Проводить кросс-валидацию на upsampled/downsampled данных – некорректно, так как баланс классов нарушен. Напомню, что внутри кросс-валидации происходит разбиение переданной в нее выборки на треин и валидацию. \n",
    "    \n",
    "В случае upsampling получается так, что в треин и в валидацию (внутри кросс-валидации) вообще попадают одни и те же объекты. \n",
    "\n",
    "Можно попробовать реализовать подход из статьи: https://kiwidamien.github.io/how-to-do-cross-validation-when-upsampling-data.html .\n",
    "    \n",
    "Если со SMOTE проблемы, то подбери параметры на валидационном наборе.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка (ревью 2):</b> Эта ошибка не исправлена.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента :</b> Убрал downsampling. Провожу кросвал после SMOTE\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель Logistic Regression (после SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solvers = ['newton-cg', 'liblinear', 'sag', 'saga']\n",
    "#for i in solvers:\n",
    "#    classificator = LogisticRegression(random_state=RND,solver= i)\n",
    "#    f1_score = cross_val_score(classificator, X_train_res, y_train_res, cv=cv_counts,\n",
    "#                               scoring='f1').mean()\n",
    "    \n",
    "#    line()\n",
    "#    print(\"solvers =\", i, \": \", end='')\n",
    "#    print('f1_score = ', f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет (ревью 3): </b> Не совсем так. По ссылке выше еще используют пайплайн, без него не удастся до конца исправить оишбку. Мы ведь хотим, чтобы апсемплинг проводился внутри кросс-валидации после разбиения данных на треин и валидацию (это я про разбиение внутри кросс-валидации).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________________________\n",
    "solvers = newton-cg : f1_score =  0.9455906597218801\n",
    "__________________________________\n",
    "solvers = liblinear : f1_score =  0.9455906597218801\n",
    "__________________________________\n",
    "solvers = sag : f1_score =  0.9455906597218801\n",
    "__________________________________\n",
    "solvers = saga : f1_score =  0.9456203819714983"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# расчет метрик качества\n",
    "#lr = LogisticRegression()\n",
    "#lr.fit(features_train, target_train.ravel())\n",
    "\n",
    "#predictions = lr.predict(features_test)\n",
    "\n",
    "#print(classification_report(target_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель Random Forest (после SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for est in range(60, 100, 20):\n",
    "#    for depth in range(60, 100, 20):\n",
    "#        classificator = RandomForestClassifier(random_state=RND, n_estimators= est, max_depth=depth)\n",
    "#        f1_score = cross_val_score(classificator, X_train_res, y_train_res, cv=cv_counts, scoring='f1').mean()\n",
    "        \n",
    "#        line()\n",
    "#        print(\"n_estimators =\", est, \": \", end='')\n",
    "#        print(\"max_depth =\", depth, \": \", end='')\n",
    "#        print('f1_score = ', f1_score)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rfc = RandomForestClassifier()\n",
    "#rfc.fit(features_train, target_train.ravel())\n",
    "\n",
    "#predictions = rfc.predict(features_test)\n",
    "\n",
    "#print(classification_report(target_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка:</b> Нужно еще измерить качество на тестовой выборке.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка (ревью 2):</b> Эта ошибка тоже не исправлена.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента :</b> Расчет метрик качества добавлен\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка (ревью 3):</b> Требуемое качество не достигнуто. Нам нужно добиться f1-score у 1-го класса >0.75. Давай сосредоточимся на модели LogisticRegression (остальыне вообще не будет запускать). Подберем к ней параметр C и, возможно, ну будем проводить апсемплинг/даунсемплинг. Это должно помочь добиться требуемого качества.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента 2:</b> Ниже привел обучение модели LogisticRegression с подбором параметра С\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression  с подбором параметра \"С\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     35902\n",
      "           1       0.87      0.69      0.77      3991\n",
      "\n",
      "    accuracy                           0.96     39893\n",
      "   macro avg       0.92      0.84      0.87     39893\n",
      "weighted avg       0.96      0.96      0.96     39893\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# без апсемплинга/даунсемплинга\n",
    "classificator = LogisticRegression()\n",
    "params = [{'solver':['newton-cg', 'liblinear'],\n",
    "                'C':[0.1, 1, 10, 100]}]\n",
    "clf = GridSearchCV(classificator, params, scoring='f1',cv=cv_counts)\n",
    "clf.fit(features_train, target_train)\n",
    "\n",
    "predictions = clf.predict(features_test)\n",
    "print(classification_report(target_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97     35902\n",
      "           1       0.66      0.81      0.73      3991\n",
      "\n",
      "    accuracy                           0.94     39893\n",
      "   macro avg       0.82      0.88      0.85     39893\n",
      "weighted avg       0.95      0.94      0.94     39893\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cо SMOTE\n",
    "classificator = LogisticRegression()\n",
    "params = [{'solver':['newton-cg', 'liblinear'],\n",
    "                'C':[0.1, 1, 10, 100]}]\n",
    "clf = GridSearchCV(classificator, params, scoring='f1',cv=cv_counts)\n",
    "clf.fit(X_train_res, y_train_res)\n",
    "\n",
    "predictions = clf.predict(features_test)\n",
    "print(classification_report(target_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95     35902\n",
      "           1       0.56      0.87      0.68      3991\n",
      "\n",
      "    accuracy                           0.92     39893\n",
      "   macro avg       0.77      0.90      0.82     39893\n",
      "weighted avg       0.94      0.92      0.93     39893\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# c даунсемплингом\n",
    "classificator = LogisticRegression()\n",
    "params = [{'solver':['newton-cg', 'liblinear'],\n",
    "                'C':[0.1, 1, 10, 100]}]\n",
    "clf = GridSearchCV(classificator, params, scoring='f1',cv=cv_counts)\n",
    "clf.fit(features_train_downsample, target_train_downsample)\n",
    "\n",
    "predictions = clf.predict(features_test)\n",
    "print(classification_report(target_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "добиться f1-score у 1-го класса >0.75 удалось лишь без апсемплинга/даунсемплинга"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента 2:</b> Не понимаю почему при даунсемплинге получается плохое качетво модели, ведь как я понял эти методы как раз призваны для того что  бы улучшать качество. Объясни, пожалуйста, почему так выходит?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для работы был предоставлен датасет 2 столбца и 159 571. \n",
    "\n",
    "Пропуски отсутствуют. Дубликатов нет. \n",
    "\n",
    "В данных наблюдается сильный дисбаланс классов в столбце toxic: 0 ~ 90% и 1 ~ 10%. Соответственно токсичных коментов всего 10%\n",
    "\n",
    "В ходе работы была проведена лематизация. Данные были поделены на выборки. Размерность выборок соблюдена.Так же была проведена векторизация текста.\n",
    "\n",
    "При обучении моделей на первом этапе для борьбы с дисбалансом применил параметр class_weight='balanced' желаемого результата добиться не удалось.\n",
    "\n",
    "На втором этапе был применен даунсемплинг. При этом все обученные модели показали себя хорошо. Лучший f1_score =  0.879 показала модель логической регресии. \n",
    "\n",
    "Модель рандом форест так же показала достаточно хороший f1_score =  0.829, но при достаточно высоких гиперпараметрах. Так же она достаточно медлительна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### upd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалось разобраться со SMOTE поэтому от downsample решил отказаться. После применения SMOTE f1_score всех обученных моделей существенно подрос по отношению к downsample. Теперь в лидерах модель Random Forest с f1_score = 0,95 чуть хуже отработала модель Logistic Regression f1_score = 0,94. Модель Decision Tree в вечных оутсайдерах хотя и показатель достаточно высокий f1_score = 0,92."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Приятно видеть подробный вывод в конце проекта.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента:</b> Подскажи, а результаты можно как то визуализировать? или тут именно цифры важны\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет (ревью 3): </b> Можно собрать все показатели по разным моделям в одну табличку. Графики строить смысла нет.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Данные загружены и подготовлены\n",
    "- [ ]  Модели обучены\n",
    "- [ ]  Значение метрики *F1* не меньше 0.75\n",
    "- [ ]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2927,
    "start_time": "2022-05-18T13:14:46.142Z"
   },
   {
    "duration": 3412,
    "start_time": "2022-05-18T13:14:49.071Z"
   },
   {
    "duration": 316,
    "start_time": "2022-05-18T13:14:59.340Z"
   },
   {
    "duration": 128,
    "start_time": "2022-05-18T13:15:00.308Z"
   },
   {
    "duration": 147,
    "start_time": "2022-05-18T13:15:07.362Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-18T13:16:07.367Z"
   },
   {
    "duration": 16,
    "start_time": "2022-05-18T13:16:11.234Z"
   },
   {
    "duration": 231,
    "start_time": "2022-05-18T13:16:59.386Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-18T13:17:24.802Z"
   },
   {
    "duration": 111761,
    "start_time": "2022-05-18T13:17:29.874Z"
   },
   {
    "duration": 107995,
    "start_time": "2022-05-18T13:20:22.490Z"
   },
   {
    "duration": 49,
    "start_time": "2022-05-18T13:23:37.626Z"
   },
   {
    "duration": 17,
    "start_time": "2022-05-18T13:32:16.463Z"
   },
   {
    "duration": 37,
    "start_time": "2022-05-18T13:32:57.737Z"
   },
   {
    "duration": 78,
    "start_time": "2022-05-18T13:33:01.888Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-18T13:37:14.398Z"
   },
   {
    "duration": 1610,
    "start_time": "2022-05-18T13:44:27.766Z"
   },
   {
    "duration": 857,
    "start_time": "2022-05-18T13:44:29.378Z"
   },
   {
    "duration": 257,
    "start_time": "2022-05-18T13:44:30.237Z"
   },
   {
    "duration": 132,
    "start_time": "2022-05-18T13:44:30.496Z"
   },
   {
    "duration": 93361,
    "start_time": "2022-05-18T13:44:30.630Z"
   },
   {
    "duration": 50,
    "start_time": "2022-05-18T13:46:03.993Z"
   },
   {
    "duration": 51,
    "start_time": "2022-05-18T13:46:04.044Z"
   },
   {
    "duration": 2095,
    "start_time": "2022-05-19T06:17:57.741Z"
   },
   {
    "duration": 2197,
    "start_time": "2022-05-19T06:17:59.838Z"
   },
   {
    "duration": 260,
    "start_time": "2022-05-19T06:18:02.046Z"
   },
   {
    "duration": 104,
    "start_time": "2022-05-19T06:18:02.308Z"
   },
   {
    "duration": 78320,
    "start_time": "2022-05-19T06:18:02.414Z"
   },
   {
    "duration": 35,
    "start_time": "2022-05-19T06:19:20.736Z"
   },
   {
    "duration": 61,
    "start_time": "2022-05-19T06:19:20.773Z"
   },
   {
    "duration": 1467,
    "start_time": "2022-05-19T06:22:50.861Z"
   },
   {
    "duration": 736,
    "start_time": "2022-05-19T06:22:52.330Z"
   },
   {
    "duration": 231,
    "start_time": "2022-05-19T06:22:53.068Z"
   },
   {
    "duration": 97,
    "start_time": "2022-05-19T06:22:53.301Z"
   },
   {
    "duration": 75571,
    "start_time": "2022-05-19T06:22:53.400Z"
   },
   {
    "duration": 52,
    "start_time": "2022-05-19T06:24:08.973Z"
   },
   {
    "duration": 66,
    "start_time": "2022-05-19T06:24:09.028Z"
   },
   {
    "duration": 151,
    "start_time": "2022-05-19T06:24:09.096Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-19T06:24:09.249Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-19T06:24:09.251Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-19T06:32:29.010Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-19T06:32:51.599Z"
   },
   {
    "duration": 2440,
    "start_time": "2022-05-19T10:35:20.270Z"
   },
   {
    "duration": 3407,
    "start_time": "2022-05-19T10:35:22.712Z"
   },
   {
    "duration": 243,
    "start_time": "2022-05-19T10:35:26.121Z"
   },
   {
    "duration": 109,
    "start_time": "2022-05-19T10:35:26.366Z"
   },
   {
    "duration": 82011,
    "start_time": "2022-05-19T10:35:26.476Z"
   },
   {
    "duration": 39,
    "start_time": "2022-05-19T10:36:48.489Z"
   },
   {
    "duration": 61,
    "start_time": "2022-05-19T10:36:48.530Z"
   },
   {
    "duration": 159,
    "start_time": "2022-05-19T10:36:48.593Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-19T10:36:48.754Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-19T10:36:48.756Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-19T10:36:48.757Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-19T10:36:48.758Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-19T10:36:48.760Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-19T10:37:49.323Z"
   },
   {
    "duration": 10414,
    "start_time": "2022-05-19T10:37:55.402Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-19T10:38:05.818Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-19T10:38:54.554Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-19T10:38:59.105Z"
   },
   {
    "duration": 99332,
    "start_time": "2022-05-19T10:39:36.145Z"
   },
   {
    "duration": 289741,
    "start_time": "2022-05-19T10:52:52.545Z"
   },
   {
    "duration": 273,
    "start_time": "2022-05-19T11:48:11.485Z"
   },
   {
    "duration": 750,
    "start_time": "2022-05-19T11:48:11.759Z"
   },
   {
    "duration": 257,
    "start_time": "2022-05-19T11:48:12.511Z"
   },
   {
    "duration": 120,
    "start_time": "2022-05-19T11:48:12.775Z"
   },
   {
    "duration": 78304,
    "start_time": "2022-05-19T11:48:12.897Z"
   },
   {
    "duration": 34,
    "start_time": "2022-05-19T11:49:31.203Z"
   },
   {
    "duration": 54,
    "start_time": "2022-05-19T11:49:31.239Z"
   },
   {
    "duration": 10223,
    "start_time": "2022-05-19T11:49:31.295Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-19T11:49:41.519Z"
   },
   {
    "duration": 62922,
    "start_time": "2022-05-19T11:49:41.524Z"
   },
   {
    "duration": 323019,
    "start_time": "2022-05-19T11:50:44.448Z"
   },
   {
    "duration": 151469,
    "start_time": "2022-05-19T11:56:07.468Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-19T12:00:05.031Z"
   },
   {
    "duration": 789,
    "start_time": "2022-05-19T12:00:05.041Z"
   },
   {
    "duration": 253,
    "start_time": "2022-05-19T12:00:05.832Z"
   },
   {
    "duration": 105,
    "start_time": "2022-05-19T12:00:06.087Z"
   },
   {
    "duration": 82740,
    "start_time": "2022-05-19T12:00:06.194Z"
   },
   {
    "duration": 42,
    "start_time": "2022-05-19T12:01:28.936Z"
   },
   {
    "duration": 60,
    "start_time": "2022-05-19T12:01:28.979Z"
   },
   {
    "duration": 10577,
    "start_time": "2022-05-19T12:01:29.041Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-19T12:01:39.620Z"
   },
   {
    "duration": 244268,
    "start_time": "2022-05-19T12:01:39.625Z"
   },
   {
    "duration": 1699,
    "start_time": "2022-05-19T12:14:23.566Z"
   },
   {
    "duration": 848,
    "start_time": "2022-05-19T12:14:25.267Z"
   },
   {
    "duration": 291,
    "start_time": "2022-05-19T12:14:26.117Z"
   },
   {
    "duration": 133,
    "start_time": "2022-05-19T12:14:26.410Z"
   },
   {
    "duration": 84769,
    "start_time": "2022-05-19T12:14:26.545Z"
   },
   {
    "duration": 38,
    "start_time": "2022-05-19T12:15:51.315Z"
   },
   {
    "duration": 51,
    "start_time": "2022-05-19T12:15:51.355Z"
   },
   {
    "duration": 10738,
    "start_time": "2022-05-19T12:15:51.408Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-19T12:16:02.148Z"
   },
   {
    "duration": 252801,
    "start_time": "2022-05-19T12:16:02.153Z"
   },
   {
    "duration": 3223014,
    "start_time": "2022-05-19T12:20:14.955Z"
   },
   {
    "duration": 153055,
    "start_time": "2022-05-19T13:13:57.971Z"
   },
   {
    "duration": 164,
    "start_time": "2022-05-19T13:49:49.542Z"
   },
   {
    "duration": 297,
    "start_time": "2022-05-19T13:50:33.040Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-19T13:50:38.159Z"
   },
   {
    "duration": 28,
    "start_time": "2022-05-19T13:51:07.669Z"
   },
   {
    "duration": 44,
    "start_time": "2022-05-19T13:51:34.202Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-19T13:52:45.100Z"
   },
   {
    "duration": 1813,
    "start_time": "2022-05-19T14:40:55.622Z"
   },
   {
    "duration": 973,
    "start_time": "2022-05-19T14:40:57.437Z"
   },
   {
    "duration": 297,
    "start_time": "2022-05-19T14:40:58.411Z"
   },
   {
    "duration": 126,
    "start_time": "2022-05-19T14:40:58.710Z"
   },
   {
    "duration": 2006,
    "start_time": "2022-05-19T14:43:01.331Z"
   },
   {
    "duration": 1073,
    "start_time": "2022-05-19T14:43:03.340Z"
   },
   {
    "duration": 320,
    "start_time": "2022-05-19T14:43:04.421Z"
   },
   {
    "duration": 136,
    "start_time": "2022-05-19T14:43:04.743Z"
   },
   {
    "duration": 101821,
    "start_time": "2022-05-19T14:43:04.882Z"
   },
   {
    "duration": 44,
    "start_time": "2022-05-19T14:44:46.705Z"
   },
   {
    "duration": 71,
    "start_time": "2022-05-19T14:44:46.752Z"
   },
   {
    "duration": 11600,
    "start_time": "2022-05-19T14:44:46.825Z"
   },
   {
    "duration": 2,
    "start_time": "2022-05-19T14:44:58.427Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-19T14:44:58.432Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-19T14:44:58.444Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-19T14:44:58.464Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-19T14:44:58.477Z"
   },
   {
    "duration": 49,
    "start_time": "2022-05-19T14:44:58.484Z"
   },
   {
    "duration": 138,
    "start_time": "2022-05-19T15:13:23.624Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-19T15:14:14.489Z"
   },
   {
    "duration": 17,
    "start_time": "2022-05-19T15:14:18.315Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-19T15:17:12.920Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-20T06:31:34.314Z"
   },
   {
    "duration": 2189,
    "start_time": "2022-05-20T07:44:38.496Z"
   },
   {
    "duration": 157,
    "start_time": "2022-05-20T07:45:49.462Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-20T07:56:04.164Z"
   },
   {
    "duration": 23,
    "start_time": "2022-05-20T07:56:04.175Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-20T07:56:04.200Z"
   },
   {
    "duration": 21,
    "start_time": "2022-05-20T07:56:13.417Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-20T07:56:38.545Z"
   },
   {
    "duration": 2942,
    "start_time": "2022-05-20T07:56:38.556Z"
   },
   {
    "duration": 458,
    "start_time": "2022-05-20T07:56:41.500Z"
   },
   {
    "duration": 123,
    "start_time": "2022-05-20T07:56:41.960Z"
   },
   {
    "duration": 106353,
    "start_time": "2022-05-20T07:56:42.085Z"
   },
   {
    "duration": 47,
    "start_time": "2022-05-20T07:58:28.444Z"
   },
   {
    "duration": 72,
    "start_time": "2022-05-20T07:58:28.493Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-20T07:58:28.566Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-20T07:58:28.580Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-20T07:58:28.581Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-20T07:58:28.583Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-20T07:58:28.584Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-20T07:58:28.585Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-20T07:58:28.586Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-20T07:58:28.587Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-20T07:58:28.588Z"
   },
   {
    "duration": 15,
    "start_time": "2022-05-20T07:58:50.347Z"
   },
   {
    "duration": 13817,
    "start_time": "2022-05-20T07:58:51.269Z"
   },
   {
    "duration": 28,
    "start_time": "2022-05-20T07:59:05.088Z"
   },
   {
    "duration": 22,
    "start_time": "2022-05-20T07:59:05.125Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-20T07:59:44.628Z"
   },
   {
    "duration": 884,
    "start_time": "2022-05-20T07:59:54.651Z"
   },
   {
    "duration": 20,
    "start_time": "2022-05-20T08:00:41.571Z"
   },
   {
    "duration": 19,
    "start_time": "2022-05-20T08:01:38.210Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-20T08:01:53.074Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-20T08:02:05.573Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T08:03:01.577Z"
   },
   {
    "duration": 20,
    "start_time": "2022-05-20T08:03:15.721Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-20T08:03:26.273Z"
   },
   {
    "duration": 49,
    "start_time": "2022-05-20T08:03:49.442Z"
   },
   {
    "duration": 19,
    "start_time": "2022-05-20T08:03:55.170Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-20T08:04:02.385Z"
   },
   {
    "duration": 43,
    "start_time": "2022-05-20T08:04:24.817Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-20T08:04:28.258Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-20T08:04:33.800Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-20T08:06:08.763Z"
   },
   {
    "duration": 35149,
    "start_time": "2022-05-20T08:06:20.492Z"
   },
   {
    "duration": 125,
    "start_time": "2022-05-20T08:10:18.455Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-20T08:26:30.840Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-20T08:35:55.541Z"
   },
   {
    "duration": 901,
    "start_time": "2022-05-20T08:35:55.550Z"
   },
   {
    "duration": 253,
    "start_time": "2022-05-20T08:35:56.453Z"
   },
   {
    "duration": 109,
    "start_time": "2022-05-20T08:35:56.708Z"
   },
   {
    "duration": 98325,
    "start_time": "2022-05-20T08:35:56.824Z"
   },
   {
    "duration": 54,
    "start_time": "2022-05-20T08:37:35.151Z"
   },
   {
    "duration": 66,
    "start_time": "2022-05-20T08:37:35.207Z"
   },
   {
    "duration": 11330,
    "start_time": "2022-05-20T08:37:35.275Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T08:37:46.606Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-20T08:37:46.612Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-20T08:37:46.635Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-20T08:37:46.640Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-20T08:37:46.646Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-20T08:37:46.653Z"
   },
   {
    "duration": 751,
    "start_time": "2022-05-20T08:37:46.662Z"
   },
   {
    "duration": 54967,
    "start_time": "2022-05-20T08:37:47.414Z"
   },
   {
    "duration": 40443,
    "start_time": "2022-05-20T08:38:42.383Z"
   },
   {
    "duration": 1807,
    "start_time": "2022-05-20T08:56:14.836Z"
   },
   {
    "duration": 897,
    "start_time": "2022-05-20T08:56:16.645Z"
   },
   {
    "duration": 262,
    "start_time": "2022-05-20T08:56:17.544Z"
   },
   {
    "duration": 131,
    "start_time": "2022-05-20T08:56:17.809Z"
   },
   {
    "duration": 98146,
    "start_time": "2022-05-20T08:56:17.942Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-20T08:57:56.089Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-20T08:57:56.091Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-20T08:57:56.092Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-20T08:57:56.093Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-20T08:57:56.095Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-20T08:57:56.096Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-20T08:57:56.097Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-20T08:57:56.099Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-20T08:57:56.100Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-20T08:57:56.101Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-20T08:57:56.102Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-20T08:57:56.125Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-20T09:01:09.983Z"
   },
   {
    "duration": 935,
    "start_time": "2022-05-20T09:01:09.993Z"
   },
   {
    "duration": 309,
    "start_time": "2022-05-20T09:01:10.930Z"
   },
   {
    "duration": 121,
    "start_time": "2022-05-20T09:01:11.240Z"
   },
   {
    "duration": 99128,
    "start_time": "2022-05-20T09:01:11.362Z"
   },
   {
    "duration": 54,
    "start_time": "2022-05-20T09:02:50.492Z"
   },
   {
    "duration": 54,
    "start_time": "2022-05-20T09:02:50.548Z"
   },
   {
    "duration": 12417,
    "start_time": "2022-05-20T09:02:50.604Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T09:03:03.026Z"
   },
   {
    "duration": 2,
    "start_time": "2022-05-20T09:03:03.031Z"
   },
   {
    "duration": 2,
    "start_time": "2022-05-20T09:03:03.034Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-20T09:03:03.041Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-20T09:03:03.056Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-20T09:03:03.063Z"
   },
   {
    "duration": 1203,
    "start_time": "2022-05-20T09:03:03.077Z"
   },
   {
    "duration": 27064,
    "start_time": "2022-05-20T09:03:04.283Z"
   },
   {
    "duration": 60597,
    "start_time": "2022-05-20T09:03:31.349Z"
   },
   {
    "duration": 56336,
    "start_time": "2022-05-20T09:06:07.177Z"
   },
   {
    "duration": 95333,
    "start_time": "2022-05-20T09:08:36.476Z"
   },
   {
    "duration": 360344,
    "start_time": "2022-05-20T09:10:51.000Z"
   },
   {
    "duration": 66,
    "start_time": "2022-05-21T02:55:16.520Z"
   },
   {
    "duration": 2329,
    "start_time": "2022-05-21T02:55:25.807Z"
   },
   {
    "duration": 145,
    "start_time": "2022-05-21T03:01:29.511Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-21T03:01:39.406Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-21T03:06:12.843Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-21T03:06:37.872Z"
   },
   {
    "duration": 2551,
    "start_time": "2022-05-21T03:06:48.501Z"
   },
   {
    "duration": 263,
    "start_time": "2022-05-21T03:06:51.054Z"
   },
   {
    "duration": 111,
    "start_time": "2022-05-21T03:06:53.914Z"
   },
   {
    "duration": 94,
    "start_time": "2022-05-21T03:06:59.984Z"
   },
   {
    "duration": 100,
    "start_time": "2022-05-21T03:07:06.642Z"
   },
   {
    "duration": 99,
    "start_time": "2022-05-21T03:07:11.503Z"
   },
   {
    "duration": 109,
    "start_time": "2022-05-21T03:07:15.559Z"
   },
   {
    "duration": 104810,
    "start_time": "2022-05-21T03:10:25.753Z"
   },
   {
    "duration": 48,
    "start_time": "2022-05-21T03:12:10.566Z"
   },
   {
    "duration": 74,
    "start_time": "2022-05-21T03:12:10.616Z"
   },
   {
    "duration": 8059,
    "start_time": "2022-05-21T03:12:10.693Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-21T03:21:10.068Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-21T03:22:20.159Z"
   },
   {
    "duration": 259,
    "start_time": "2022-05-21T03:23:54.998Z"
   },
   {
    "duration": 5731,
    "start_time": "2022-05-23T07:54:55.778Z"
   },
   {
    "duration": 3422,
    "start_time": "2022-05-23T07:56:02.695Z"
   },
   {
    "duration": 2974,
    "start_time": "2022-05-23T07:56:18.199Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-23T07:57:54.404Z"
   },
   {
    "duration": 16,
    "start_time": "2022-05-23T07:58:19.498Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-23T07:58:24.180Z"
   },
   {
    "duration": 2181,
    "start_time": "2022-05-23T07:58:25.723Z"
   },
   {
    "duration": 322,
    "start_time": "2022-05-23T07:58:29.051Z"
   },
   {
    "duration": 99,
    "start_time": "2022-05-23T07:58:30.115Z"
   },
   {
    "duration": 4475,
    "start_time": "2022-05-24T13:22:40.487Z"
   },
   {
    "duration": 5165,
    "start_time": "2022-05-24T13:22:55.328Z"
   },
   {
    "duration": 1947,
    "start_time": "2022-05-24T13:23:38.449Z"
   },
   {
    "duration": 39,
    "start_time": "2022-05-24T13:40:08.754Z"
   },
   {
    "duration": 1527,
    "start_time": "2022-05-24T13:44:28.372Z"
   },
   {
    "duration": 42,
    "start_time": "2022-05-24T13:44:29.902Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:29.946Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:29.947Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:29.948Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:29.949Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:29.950Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:29.951Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:29.952Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:29.953Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:29.954Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:29.955Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:29.956Z"
   },
   {
    "duration": 1,
    "start_time": "2022-05-24T13:44:29.957Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:29.959Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:29.960Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:29.961Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:29.962Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:29.963Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:29.964Z"
   },
   {
    "duration": 2325,
    "start_time": "2022-05-24T13:44:36.351Z"
   },
   {
    "duration": 2414,
    "start_time": "2022-05-24T13:44:38.679Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-24T13:44:41.095Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:41.101Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:41.102Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:41.103Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:41.104Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:41.105Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:41.106Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:41.107Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:41.108Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:41.109Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:41.110Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:41.111Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:41.111Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:41.113Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:41.113Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:41.114Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:41.115Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T13:44:41.116Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-24T13:45:03.409Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-24T13:45:11.570Z"
   },
   {
    "duration": 128,
    "start_time": "2022-05-24T13:57:24.191Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-24T13:57:36.323Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-24T13:57:46.734Z"
   },
   {
    "duration": 3049,
    "start_time": "2022-05-24T13:57:48.683Z"
   },
   {
    "duration": 260,
    "start_time": "2022-05-24T13:57:51.734Z"
   },
   {
    "duration": 117,
    "start_time": "2022-05-24T13:57:51.995Z"
   },
   {
    "duration": 84363,
    "start_time": "2022-05-24T13:57:58.626Z"
   },
   {
    "duration": 51,
    "start_time": "2022-05-24T13:59:22.991Z"
   },
   {
    "duration": 57,
    "start_time": "2022-05-24T13:59:29.482Z"
   },
   {
    "duration": 6951,
    "start_time": "2022-05-24T13:59:30.304Z"
   },
   {
    "duration": 2,
    "start_time": "2022-05-24T13:59:37.258Z"
   },
   {
    "duration": 2,
    "start_time": "2022-05-24T13:59:37.392Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-24T13:59:39.792Z"
   },
   {
    "duration": 2,
    "start_time": "2022-05-24T13:59:42.057Z"
   },
   {
    "duration": 2,
    "start_time": "2022-05-24T13:59:42.567Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-24T13:59:45.369Z"
   },
   {
    "duration": 2173,
    "start_time": "2022-05-24T13:59:51.376Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-24T14:03:16.167Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-24T14:06:30.458Z"
   },
   {
    "duration": 1786,
    "start_time": "2022-05-24T14:06:30.464Z"
   },
   {
    "duration": 802,
    "start_time": "2022-05-24T14:06:32.252Z"
   },
   {
    "duration": 256,
    "start_time": "2022-05-24T14:06:33.056Z"
   },
   {
    "duration": 110,
    "start_time": "2022-05-24T14:06:33.313Z"
   },
   {
    "duration": 84554,
    "start_time": "2022-05-24T14:06:33.425Z"
   },
   {
    "duration": 44,
    "start_time": "2022-05-24T14:07:57.981Z"
   },
   {
    "duration": 45,
    "start_time": "2022-05-24T14:07:58.027Z"
   },
   {
    "duration": 6751,
    "start_time": "2022-05-24T14:07:58.074Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-24T14:08:04.826Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-24T14:08:04.830Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-24T14:08:04.838Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-24T14:08:04.852Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-24T14:08:04.860Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-24T14:08:04.867Z"
   },
   {
    "duration": 2175,
    "start_time": "2022-05-24T14:08:04.875Z"
   },
   {
    "duration": 511699,
    "start_time": "2022-05-24T14:08:07.052Z"
   },
   {
    "duration": 184,
    "start_time": "2022-05-24T14:16:38.753Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T14:16:38.939Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T14:16:38.941Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T14:16:38.942Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-24T14:16:38.943Z"
   },
   {
    "duration": 172846,
    "start_time": "2022-05-24T15:17:30.922Z"
   },
   {
    "duration": 83679,
    "start_time": "2022-05-24T15:20:27.697Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-24T15:22:00.974Z"
   },
   {
    "duration": 39031,
    "start_time": "2022-05-24T15:22:34.927Z"
   },
   {
    "duration": 926974,
    "start_time": "2022-05-24T15:23:26.761Z"
   },
   {
    "duration": 229279,
    "start_time": "2022-05-24T15:39:09.038Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-25T08:47:26.861Z"
   },
   {
    "duration": 2354,
    "start_time": "2022-05-25T08:47:26.868Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-25T08:47:29.224Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-25T08:47:29.225Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-25T08:47:29.226Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-25T08:47:29.228Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-25T08:47:29.229Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-25T08:47:29.230Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-25T08:47:29.241Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-25T08:47:29.242Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-25T08:47:29.244Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-25T08:47:29.244Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-25T08:47:29.246Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-25T08:47:29.247Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-25T08:47:29.247Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-25T08:47:29.248Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-25T08:47:29.249Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-25T08:47:29.250Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-25T08:47:29.251Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-25T08:47:29.252Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-25T08:47:29.253Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-25T08:47:29.254Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-25T08:47:29.255Z"
   },
   {
    "duration": 1747,
    "start_time": "2022-05-25T08:50:00.262Z"
   },
   {
    "duration": 5967,
    "start_time": "2022-05-25T08:50:18.539Z"
   },
   {
    "duration": 5176,
    "start_time": "2022-05-25T08:50:39.640Z"
   },
   {
    "duration": 1578,
    "start_time": "2022-05-25T08:51:07.793Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-25T08:51:16.941Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-25T08:51:16.947Z"
   },
   {
    "duration": 3399,
    "start_time": "2022-05-25T08:51:16.958Z"
   },
   {
    "duration": 234,
    "start_time": "2022-05-25T08:51:20.358Z"
   },
   {
    "duration": 104,
    "start_time": "2022-05-25T08:51:20.594Z"
   },
   {
    "duration": 83263,
    "start_time": "2022-05-25T08:51:20.699Z"
   },
   {
    "duration": 40,
    "start_time": "2022-05-25T08:52:43.964Z"
   },
   {
    "duration": 78,
    "start_time": "2022-05-25T08:52:44.006Z"
   },
   {
    "duration": 6809,
    "start_time": "2022-05-25T08:52:44.086Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-25T08:52:50.897Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-25T08:52:50.901Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-25T08:52:50.916Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-25T08:52:50.927Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-25T08:52:50.936Z"
   },
   {
    "duration": 16,
    "start_time": "2022-05-25T08:52:50.944Z"
   },
   {
    "duration": 2239,
    "start_time": "2022-05-25T08:52:50.962Z"
   },
   {
    "duration": 2,
    "start_time": "2022-05-25T08:52:53.203Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-25T08:52:53.207Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-25T08:52:53.220Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-25T08:52:53.230Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-25T08:52:53.238Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-25T08:52:53.248Z"
   },
   {
    "duration": 138,
    "start_time": "2022-05-25T08:52:53.262Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-25T08:57:54.739Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-25T09:03:20.174Z"
   },
   {
    "duration": 366193,
    "start_time": "2022-05-25T09:03:57.248Z"
   },
   {
    "duration": 203806,
    "start_time": "2022-05-25T09:10:41.490Z"
   },
   {
    "duration": 343692,
    "start_time": "2022-05-25T09:14:52.448Z"
   },
   {
    "duration": 346526,
    "start_time": "2022-05-25T09:20:55.371Z"
   },
   {
    "duration": 681784,
    "start_time": "2022-05-25T09:30:19.580Z"
   },
   {
    "duration": 2,
    "start_time": "2022-05-25T09:43:14.797Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-25T09:43:14.805Z"
   },
   {
    "duration": 815,
    "start_time": "2022-05-25T09:43:14.813Z"
   },
   {
    "duration": 233,
    "start_time": "2022-05-25T09:43:15.630Z"
   },
   {
    "duration": 89,
    "start_time": "2022-05-25T09:43:15.864Z"
   },
   {
    "duration": 79514,
    "start_time": "2022-05-25T09:43:15.956Z"
   },
   {
    "duration": 36,
    "start_time": "2022-05-25T09:44:35.472Z"
   },
   {
    "duration": 54,
    "start_time": "2022-05-25T09:44:35.509Z"
   },
   {
    "duration": 6444,
    "start_time": "2022-05-25T09:44:35.565Z"
   },
   {
    "duration": 2,
    "start_time": "2022-05-25T09:44:42.011Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-25T09:44:42.015Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-25T09:44:42.030Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-25T09:44:42.041Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-25T09:44:42.048Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-25T09:44:42.056Z"
   },
   {
    "duration": 3608,
    "start_time": "2022-05-25T09:44:42.064Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-25T09:44:45.674Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-25T09:44:45.678Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-25T09:44:45.686Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-25T09:44:45.692Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-25T09:44:45.698Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-25T09:44:45.705Z"
   },
   {
    "duration": 314383,
    "start_time": "2022-05-25T09:44:45.710Z"
   },
   {
    "duration": 609976,
    "start_time": "2022-05-25T09:50:00.095Z"
   },
   {
    "duration": 31,
    "start_time": "2022-05-25T10:04:46.015Z"
   },
   {
    "duration": 574,
    "start_time": "2022-05-25T10:11:02.154Z"
   },
   {
    "duration": 89961,
    "start_time": "2022-05-25T10:12:45.332Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
